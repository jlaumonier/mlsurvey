Concepts
========

#. Context of a supervised learning

    #. Data : for classification : x, y
    #. Algorithm :

        #. Operation : Init, set Hyperparameters, Learn
        #. Defintion

            #. Predictor family
            #. Loss function
            #. Optimization method

        #. Hyperparameters

    #. Datasets

#. Result : results of the algorithm
#. Visualization with bokeh

Datasets
========

Some datasets are defined : Iris (REF), N-class Random data (REF) based on scikit learn.
DataSetFactory can be used to create a DataSet from the name of the dataset
A DataSet can be affected to an input to feed the algorithm
Some parameters are defined for some datasets. Not all parameters defined in sckitlearn can be used

Existing datasets
-----------------

1. N Class Random : Make a n class random problem (from sklearn.datasets) with noise calculation
1. Any datasets in sklearn.datasets (in theory)

Exporting results
=================

Results of a learning (input. classifiers, evalution, config) can be stored as json files into a directory Logs/(datehour)/
The results can be loaded be the supervised learning workflow and can be show by Visualization

Configuration
=============

The configuration of the learning process is defined in the config/config.json and can be loaded and accessed 
from the mlsurvey.Config class. Each element in the learning_process section can be a list to launch multiple learning.

The config file in json may contains any type and tuple with the following form 
{'__type__': '__tuple__', '__value__' : '(1,2,3,4)'}. While loading the config file, the class Config insure that the 
tuple-dict-form are transformed to a real python tuple


Learning process
================

The supervised learning process follow this structure :
1. choose the dataset (generate, load, define)
1. input pretreatement (support StandartScaler (mean 0, stddev 1))
1. apply the model evaluation strategy to split the input (support Train+Test)
1. learn
1. model evaluation and metrics calculation (confusion matrix, TODO)

The multiple learning workflow run multiple supervised learning workflow according to the config file. Multiple 
configuration can be generated by adding a list instead of a single value in a parameter for datasets, algorithms 
and splits.

Visualization
=============

The main_visualize.py program read the logs/ directory and open a web page (using dahs and flask) to visualize 
all learning results as a table after clicking the 'Search' button. The user can choose one or more result to displav them.
Each time the user select one result, the web ui uses the visualization process to generate the visualization component.
The user can add multiple criteria in addition to algorithm and dataset to filter the results. After the criteria selection,
if there is only one parameter with at least 2 possible value, a figure is displayed to show the score.

Visualization process
---------------------

From a log directory with config.json, evaluation.json, input.json and model.joblib, the visualization process
create dash component for config, graph and evaluation to display dataset, classification, configuration 
and score of the learning process. Test data are also displayed with the true label and the predicted labels

Fairness process
================

Fairness process calculate only the demographic parity and the disparate impact rate on all the dataset. Moreover if the fairness process is a subprocess of a supervised learning process, equal opportunity, statistical parit and average equalized odds are also calculated. To do so, add a fairness parameter at the end of the dataset definition, in supervised learning process config file :

::

"fairness": {
"protected_attribute": <num column of protected attribute>,
"privileged_classes": "<condition on x>"}

the condition on x is a test such as "x >= 10" or "x == 'one_value'"

Error management
================

Three exceptions are used
1. ConfigError : Raised when an error occurs related to the content of the config files
1. ModelError: Raised during models processing
1. WorkflowError : Raised during workflow treatment