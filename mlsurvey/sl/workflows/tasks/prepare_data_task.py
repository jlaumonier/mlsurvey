from sklearn.preprocessing import StandardScaler

from kedro.pipeline import node

from mlsurvey.workflows.tasks import BaseTask


class PrepareDataTask(BaseTask):
    """
    prepare data from raw data generated by LoadDataTask
    """

    @classmethod
    def log_inputs_outputs(cls, log, d):
        # Log inside sub directory
        log.set_sub_dir(str(cls.__name__))
        inputs = {'data': d['prepared_data']}
        log.save_input(inputs, metadata_filename='data.json')
        log.set_sub_dir('')

    @staticmethod
    def prepare_data(config, log, raw_data):
        # convert categorical to int
        cat_columns = raw_data.df.select_dtypes(['object']).columns
        if not cat_columns.empty:
            raw_data.df[cat_columns] = raw_data.df[cat_columns].astype('category')
            raw_data.df[cat_columns] = raw_data.df[cat_columns].apply(lambda c: c.cat.codes)

        x_transformed = StandardScaler().fit_transform(raw_data.x)
        prepared_data = raw_data.copy_with_new_data([x_transformed, raw_data.y])

        # Logging
        d = {'prepared_data': prepared_data}
        PrepareDataTask.log_inputs_outputs(log, d)

        return [prepared_data]

    @classmethod
    def get_node(cls):
        return node(PrepareDataTask.prepare_data, inputs=['config', 'log', 'raw_data'], outputs=['prepared_data'])
