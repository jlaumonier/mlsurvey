import luigi
from sklearn.preprocessing import StandardScaler

import mlsurvey as mls


class PrepareDataTask(luigi.Task):
    """
    prepare data from raw data generated by LoadDataTask
    """
    logging_base_directory = luigi.Parameter()
    logging_directory = luigi.Parameter()
    config_directory = luigi.Parameter()
    config_filename = luigi.Parameter()
    log = None
    config = None

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # init log and config
        self.init_log_config()

    def init_log_config(self):
        """
        Initialized log and config
        """
        self.log = mls.Logging(dir_name=self.logging_directory, base_dir=self.logging_base_directory)
        self.config = mls.Config(name=self.config_filename, directory=self.config_directory)

    def requires(self):
        return mls.sl.workflows.tasks.LoadDataTask(logging_directory=self.logging_directory,
                                                   logging_base_directory=self.logging_base_directory,
                                                   config_filename=self.config_filename,
                                                   config_directory=self.config_directory)

    def run(self):
        """
        Run the task
        """
        loaded_data = self.log.load_input(self.input()['raw_data'].filename)
        raw_data = loaded_data['raw_data']
        x_transformed = StandardScaler().fit_transform(raw_data.x)
        data = raw_data.copy_with_new_data([x_transformed, raw_data.y])
        data_to_save = {'data': data}
        self.log.save_input(data_to_save, metadata_filename=self.output()['data'].filename)

    def output(self):
        data_json_filename = 'data.json'
        target_data = mls.sl.workflows.tasks.FileDirLocalTarget(directory=self.log.directory,
                                                                filename=data_json_filename)
        target = {'data': target_data}
        return target
